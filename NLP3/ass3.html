
<HTML> 
<HEAD> 
<meta content="text/html;charset=utf-8" http-equiv="Content-Type">
<link rel="stylesheet" href="nlp.css" type="text/css" media="all" /> 
<br>
<TITLE>NLP12 Assignment 3: NER, Parsing</TITLE> 
</HEAD> 

<BODY> 
<h1>Assignment 3</h1>
<b>Shimi Malka 066461641</b>
<br>
<b>Netali Alima 300712742</b>

<h2>Our Solutions: </h2>

This assignment covers 2 topics: 

<ol>
<li><a href="#svm">Machine Learning methods (SVM) for Named Entity Recognition</a></li>
<li><a href="#parsing">CFG Parsing</a></li>
</ol>
<hr/>

<a name="svm"></a>
<h2>Named Entity Recognition with SVM</h2>

<h3>Named Entity Recognition</h3>


<hr/>

<a name="parsing"></a>
<h2>Question 2: PCFG Parsing</h2>

<a name="q2.1"></a>
<h3>Question 2.1: Random PCFG Generation</h3>


<a name="q2.2"></a> 
<h3>Question 2.2: Learn a PCFG from a Treebank</h3> 

<pre> 
import nltk
import nltk.grammar as gram
from nltk.probability import DictionaryProbDist , FreqDist
from nltk.grammar import WeightedGrammar , WeightedProduction , Nonterminal
from nltk.corpus import LazyCorpusLoader, BracketParseCorpusReader , simplify_wsj_tag
import matplotlib.pyplot as plt
import numpy as np

# filter NONE noneterminal from the tree
def filter_NONE(tree):
    if isinstance(tree, str):
        return tree
    if tree.node =='-NONE-':
        return None
    f_childrens = []
    for child in tree[0:]:
        c = filter_NONE(child)
        if c != None :
            f_childrens.append(c)
    if len(f_childrens) == 0: return None
    return nltk.Tree(tree.node,f_childrens)

# create Weighted Grammar for given productions
def createWG(productions):
    pcount = {} 
    lcount = {}
    for prod in productions:
        lcount[prod.lhs()] = lcount.get(prod.lhs(), 0) + 1
        pcount[prod] = pcount.get(prod, 0) + 1
    
    prods = [WeightedProduction(p.lhs(), p.rhs(), 
             prob=float(pcount[p]) / lcount[p.lhs()]) for 
             p in pcount]
    learned_pcfg_cnf = WeightedGrammar(Nonterminal('S'), prods)
    return learned_pcfg_cnf


# - treebank is the nltk.corpus.treebank lazy corpus reader
# - n indicates the number of trees to read
# - return an nltk.WeigthedGrammar
def pcfg_learn(treebank, n):
    productions = []
    treebank_interior_nodes = 0;
    
    for item in treebank.items[:n]:
        for tree in treebank.parsed_sents(item):
            treebank_interior_nodes += len(tree.productions()) + len(tree.leaves())
            tree = filter_NONE(tree)
            if tree!= None:
                productions += tree.productions()
            
    learned_pcfg = createWG( productions)

    plot_dist_productions_by_frequency(productions)
    print 'How many productions are learned from the trees? %d ' % len(learned_pcfg.productions())
    print 'How many interior nodes were in the treebank?    %d ' % treebank_interior_nodes
    return  learned_pcfg

#-- treebank is the nltk.corpus.treebank lazy corpus reader (simplified tags)
#-- n indicates the number of trees to read
#-- return an nltk.WeigthedGrammar in CNF
def pcfg_cnf_learn(treebank, n):
    productions = []
    treebank_interior_nodes = 0
    cnf_interior_nodes = 0
    
    for item in treebank.items[:n]:
        for tree in treebank.parsed_sents(item):
            treebank_interior_nodes += len(tree.productions()) + len(tree.leaves())
            tree = filter_NONE(tree)
            if tree!= None:
                tree.chomsky_normal_form(horzMarkov = 2)
                cnf_interior_nodes += len(tree.productions()) + len(tree.leaves())
                productions += tree.productions()
            
    learned_pcfg_cnf = createWG(productions)
    
    print 'How many productions are learned from the CNF trees?   %d ' % len(learned_pcfg_cnf.productions())
    print 'How many interior nodes were in the original treebank? %d ' %  treebank_interior_nodes
    print 'How many interior nodes were in the CNF treebank?      %d ' % cnf_interior_nodes
    return learned_pcfg_cnf 

def plot_dist_productions_by_frequency(productions):
    f= FreqDist(productions)
    fdd = FreqDist(f.values())
    x = []
    y = []
    for k in fdd.keys():
        x.append(k)
        y.append(fdd[k])
    plt.plot(x,y,lw=2,color= 'b')
    plt.title('Productions by frequency' )
    plt.xlabel('frequency')
    plt.ylabel('number of rules with frequency')
    plt.show()

# determines whether a tree can be parsed by a grammar
# tests that a given tree can be produced by a grammar
def cover_tree(grammar, tree):
    for pt in tree.productions():
        found = False
        for pg in grammar.productions():
            if (pt.rhs()== pg.rhs()) & (pt.lhs()==pg.lhs()):
                found = True 
                break
        if not found :
            return False
    return True

# keep only the F most frequent rules out of the N rules in the PCFG
# return the number of trees "missed" by the new pcfg
def count_misses(pcfg,treebank,n):
    misses = 0
    for item in treebank.items[:n]:
        for tree in treebank.parsed_sents(item):
            tree = filter_NONE(tree)
            if not cover_tree(pcfg, tree):
                misses +=1
    return misses


# Assume we "cut" the tail of the learned PCFG, that is we remove the least frequent rules,
# so that we keep only the F most frequent rules out of the N rules in the PCFG
# Draw a plot that indicates the number of trees "missed" 
# as the number of rules is reduced (sample every 10% of the size of the grammar).   
def plot_misses(pcfg,treebank,n):
    productions = []
    for item in treebank.items[:n]:
        for tree in treebank.parsed_sents(item):
            tree = filter_NONE(tree)
            if tree!= None:
                productions += tree.productions()
    fk= FreqDist(productions).keys()
    
    x = []
    y = []
    for reduced in np.arange(10):
        F = int(len(fk)*(reduced*0.1))
        x.append(F)
        prodsTake = list(productions)
        for k in fk[len(fk)-F:]:
            prodsTake.remove(k)
        if len(prodsTake)==0:
            y.append(len(prodsTake))
            continue
        cutPcfg = createWG(prodsTake)
        y.append(count_misses(cutPcfg,treebank,n))
        
    plt.plot(x,y,lw=1.5,color= 'b')
    plt.title('cut the tail of the learned PCFG' )
    plt.xlabel('F cuted from pcfg')
    plt.ylabel('misses')
    plt.show()     
    
     
def main():    
    n = 20
    treebank = LazyCorpusLoader('treebank/combined', BracketParseCorpusReader, 
                                r'wsj_.*\.mrg', tag_mapping_function=simplify_wsj_tag)
    print "--PCFG--" 
    learned_pcfg = pcfg_learn(treebank, n)
    plot_misses(learned_pcfg,treebank,n) 
    print "\n--CNF PCFG--" 
    learned_pcfg_cnf = pcfg_cnf_learn(treebank, n) 
    
if __name__ == '__main__':
    main() 
</pre> 

<h4>Data Exploration and Validation</h4>
Output:<br>
--PCFG--<br>
How many productions are learned from the trees? 2982<br> 
How many interior nodes were in the treebank?    16543<br>
<img src="q2_2a.PNG" width="600" height="480" />
<img src="q2_2b.PNG" width="600" height="480" />

<h4>CNF PCFG</h4>
Output:<br>
--PCFG--<br>
How many productions are learned from the trees? 2982<br> 
How many interior nodes were in the treebank?    16543 <br>

--CNF PCFG--
How many productions are learned from the CNF trees?   3535 
How many interior nodes were in the original treebank? 16543 
How many interior nodes were in the CNF treebank?      17373

<a name="q2.3"></a> 
<h3>Question 2.3: Test CFG Independence Assumptions</h3> 

<a name="q2.4"></a> 
<h3>Question 2.4: Learn a bigram Language Model</h3> 

<a name="q2.5"></a> 
<h3>Question 2.5: Validation of PCFG Generated text using an n-gram Model</h3> 

<BR> 
<HR>
 <br>
</BODY>



