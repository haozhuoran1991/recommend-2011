
<HTML> 
<HEAD> 
<meta content="text/html;charset=utf-8" http-equiv="Content-Type">
<link rel="stylesheet" href="nlp.css" type="text/css" media="all" /> 
<br>
<TITLE>NLP12 Assignment 2: Bayesian Curve Fitting, Classification</TITLE> 
</HEAD> 
 
<BODY> 
 
<h1>Assignment 2</h1>

<b>Shimi Malka 066461641</b>
<br>
<b>Netali Alima 300712742</b>

<h2>Our Solutions: </h2>
<ol>
<li>Polynomial Curve Fitting
   <ol>
   <li><a href="#syntheticdata">Synthetic Dataset Generation</a></li>
   <li><a href="#curvefitting">Polynomial Curve Fitting</a></li>
   <li><a href="#regularization">Polynomial Curve Fitting with Regularization</a></li>
   <li><a href="#q1_4">Probabilistic Regression Framework</a></li>
   <li><a href="#q1_5">Use Bayesian estimation to produce an interval estimation of the function y</a></li>
   </ol>
</li>
<li>Classification for Sentiment Analysis
   <ol>
   <li><a href="#q2_1">Baseline - Bag of words classifier</a></li>
   <li><a href="#q2_2">Data Exploration: Impact of Unknown Words</a></li>
   <li><a href="#q2_3">Improved feature extraction 1: most frequent, stop words</a></li>
   <li><a href="#q2_4">Improved feature extraction 2: exploit part of speech information</a></li>
   <li><a href="#q2_5">Improved feature extraction 3: bigrams</a></li>
   </ol>
</li>
</ol>

<h2>Q1: Polynomial Curve Fitting</h2>

<a name="syntheticdata"></a>
<h3>Q1.1 Synthetic Dataset Generation</h3>
<pre>
import matplotlib.pyplot as plt
import math
import numpy as np

def generateDataset(N, f, sigma):
    x =np.linspace(0.0, 1.0, num=N) # (that is, x1 = 0, x2=1/N-1, x3=2/N-1..., xN = 1.0)
    t = [f(xi) + np.random.normal(0.0, sigma, 1)[0] for xi in x]
    return (x,t)

def makePlot(N, f, x, t):
    vf = np.vectorize(f)
    y = vf(x)
    sizes = [40,50,70]
    fig = plt.figure()
    ax = fig.add_subplot(111)
    ax.scatter(x,t, s=sizes,marker = '.', facecolor='red' )
    plt.plot(x,y)
    plt.show()
 
 
def main():
    N = 50
    f = math.sin
    (x,t) = generateDataset(N, f, 0.03);
    makePlot(N, f, x, t)
    
if __name__ == '__main__':
    main()   
</pre>
<img src="q1_1.PNG" width="600" height="480" />

<a name="curvefitting"></a>
<h3>Q1.2 Polynomial Curve Fitting</h3>
<pre>
import numpy as np
import matplotlib.pyplot as plt
import scipy.linalg
import math

def generateDataset(N, f, sigma):
    x =np.linspace(0.0, 1.0, num=N) # (that is, x1 = 0, x2=1/N-1, x3=2/N-1..., xN = 1.0)
    t = [f(xi) + np.random.normal(0.0, sigma, 1)[0] for xi in x]
    return (x,t)

# y(x) = w0 + w1x + w2x^2 + ... + wMx^M
def Y(w,x):
    return [sum([wk*(math.pow(xi,k)) for k,wk in enumerate(w)])  for xi in x]

# E(w) = 0.5*sum(y(xi) - ti)^2 = 0.5*sum(sum(wk*xi^k) - ti)^2
def least_squares(w,x,t):
    return 0.5*sum([math.pow(sum([wk*(math.pow(xi,k)) for k,wk in enumerate(w)]) - ti , 2) for xi,ti in zip(x,t)])

# returns the optimal polynomial of degree M that approximates the dataset 
# according the least squares objective
#    W_LS = ((AT*A)^-1)*AT*t
#    A is a matrix of dimension NxM, W is a vector of dimension M and t is a vector of dimension N.)
def OptimizeLS(x, t, M):
    design_matrix = np.array([np.array([math.pow(xi,m) for m in np.arange(M+1)]) for xi in x])  # This is A
    prod = np.dot(design_matrix.T, design_matrix)      # prod is (AT*A)
    i = np.linalg.inv(prod)                            # i is (AT*A)^-1)
    m = np.dot(i, design_matrix.T)                     # m is ((AT*A)^-1)*AT
    W_LS = np.dot(m, t)                                # w is ((AT*A)^-1)*AT*t
    return W_LS

def makeSinPlot(x,t,f,M,c):
    vf = np.vectorize(f)
    y = vf(x)
    fig = plt.figure()
    wls = OptimizeLS(x, t, M)
    w = Y(wls,x)
    sizes = [40,50,70]
    ax = fig.add_subplot(111)
    ax.scatter(x,t, s=sizes,marker = '.', facecolor='red' )
    plt.title('M = %d' % M)
    plt.plot(x,w,c)
    plt.plot(x,y,'k-')
    plt.show()
    
def main():
    N = 10
    f = math.sin
    (x,t) = generateDataset(N, f, 0.03);
    makeSinPlot(x,t,f,1,'r-')
    makeSinPlot(x,t,f,3,'y-')
    makeSinPlot(x,t,f,5,'g-')
    makeSinPlot(x,t,f,9,'b-')
    print "E(w1) =  %.8f" % least_squares(OptimizeLS(x, t, 1),x,t)
    print "E(w3) =  %.8f" % least_squares(OptimizeLS(x, t, 3),x,t)
    print "E(w5) =  %.8f" % least_squares(OptimizeLS(x, t, 5),x,t)
    print "E(w9) =  %.8f" % least_squares(OptimizeLS(x, t, 9),x,t)
    
if __name__ == '__main__':
    main()  
</pre>
<img src="q1_2a.PNG" width="600" height="480" />
<img src="q1_2b.PNG" width="600" height="480" />
<img src="q1_2c.PNG" width="600" height="480" />
<img src="q1_2d.PNG" width="600" height="480" />
<br>
Least Squares Error:<br> 
E(w1) =  0.00376178<br>
E(w3) =  0.00160914<br>
E(w5) =  0.00147821<br>
E(w9) =  0.00000047<br>
<b>So M=9 is the best and it overfitting to sin(x)</b>

<a name="regularization"></a>
<h3>Q1.3 Polynomial Curve Fitting with Regularization</h3>

<a name="q1_4"></a>
<h3>Q1.4 Probabilistic Regression Framework</h3>

<a name="q1_5"></a>
<h3>Q1.5 Use Bayesian estimation to produce an interval estimation of the function y</h3>

<h2>Q2: Classification for Sentiment Analysis</h2>

<a name="q2_1"></a>
<h3>Q2.1: Baseline - Bag of words classifier</h3>

<a name="q2_2"></a>
<h3>Q2.2: Data Exploration: Impact of Unknown Words</h3>

<a name="q2_3"></a>
<h3>Q2.3: Improved feature extraction 1: most frequent, stop words</h3>

<a name="q2_4"></a>
<h3>Q2.4: Improved feature extraction 2: exploit part of speech information</h3>

<a name="q2_5"></a>
<h3>Q2.5: Improved feature extraction 3: bigrams</h3>

<BR> 
<HR>
 <br>
</BODY>

